{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1732181925083,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "NZLKEFGqpkza"
   },
   "outputs": [],
   "source": [
    "from random import randint, choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kMDITdMpkzc"
   },
   "source": [
    "# Map Reduce\n",
    "\n",
    "In the part of the assignment you are requested to use Map Reduce paradigm to solve the following exercises.\n",
    "\n",
    "**NOTE THAT**: **A solution that does not use map reduce is not valid!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UvFKq5Dpkzd"
   },
   "source": [
    "# Exercise 1\n",
    "\n",
    "You have a list of dictionaries, each representing a student with the following properties: a name and an array of test scores. Your task is to use map, filter, and reduce to calculate the average test score for each student, and then return a list of dictionaries containing only the students whose average score is above 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "XnZxeOdtpkze"
   },
   "outputs": [],
   "source": [
    "students = [\n",
    "    {\"name\": \"Alice\", \"scores\": [95, 92, 88, 100]},\n",
    "    {\"name\": \"Bob\", \"scores\": [78, 81, 85, 80]},\n",
    "    {\"name\": \"Charlie\", \"scores\": [99, 91, 94, 96]},\n",
    "    {\"name\": \"Diana\", \"scores\": [85, 87, 89, 83]}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WopOVxHSpkzf"
   },
   "source": [
    "Use `map`, `reduce` and `filter` that produce an output like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JGYCqweYpkzf",
    "outputId": "89230ab4-a15a-4ae5-84a3-9eb13573a4a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Alice', 'average_score': 93.75},\n",
       " {'name': 'Charlie', 'average_score': 95.0}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    {\"name\": \"Alice\", \"average_score\": 93.75},\n",
    "    {\"name\": \"Charlie\", \"average_score\": 95.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TG5h3pN1pkzg"
   },
   "source": [
    "### Test\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1732181928585,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "3ZB3sFT_pkzh",
    "outputId": "cf486e14-4d6f-455d-8f69-19096dfe9831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Student 1', 'scores': [91, 98, 65, 100, 57]},\n",
       " {'name': 'Student 2', 'scores': [65, 74, 72, 100, 70, 69]},\n",
       " {'name': 'Student 3', 'scores': [88, 91, 92, 79]}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_student_dataset(num_students=50):\n",
    "    names = [f\"Student {i}\" for i in range(1, num_students + 1)]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": name,\n",
    "            \"scores\": [randint(50, 100) for _ in range(randint(3, 6))]  # Random scores between 50 and 100\n",
    "        }\n",
    "        for name in names\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "random_student_dataset = generate_random_student_dataset(50)\n",
    "random_student_dataset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "MHi3FLeWpkzi"
   },
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "from functools import reduce\n",
    "students = [\n",
    "    {'name': 'Student 1', 'scores': [69, 50, 98, 54]},\n",
    "    {'name': 'Student 2', 'scores': [69, 74, 71]},\n",
    "    {'name': 'Student 3', 'scores': [89, 60, 88, 56, 63]}\n",
    "]\n",
    "\n",
    "def calculate_average(student):\n",
    "    total_score = reduce(lambda x,y: x+y, student['scores'])\n",
    "    avg_score = total_score / len(student['scores'])\n",
    "    return {**student, 'average_score': avg_score}\n",
    "\n",
    "students_with_avg= list(map(calculate_average, students))\n",
    "\n",
    "high_achievers = list(filter(lambda student: student ['average_score']>90, students_with_avg))\n",
    "\n",
    "for student in high_achievers:\n",
    "    print(student)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWL_3xWNpkzj"
   },
   "source": [
    "## Exercise 2\n",
    "\n",
    "You have a list of dictionaries, each representing a product with the following properties: name, price, and category. Using the functions `map`, `filter`, and `reduce`, calculate the average price of the products in each category and return a list of dictionaries containing only the categories where the average price exceeds 50.\n",
    "\n",
    "Example input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "wwk7f8Ihpkzk"
   },
   "outputs": [],
   "source": [
    "products = [\n",
    "    {\"name\": \"Product A\", \"price\": 60, \"category\": \"Electronics\"},\n",
    "    {\"name\": \"Product B\", \"price\": 40, \"category\": \"Electronics\"},\n",
    "    {\"name\": \"Product C\", \"price\": 70, \"category\": \"Home\"},\n",
    "    {\"name\": \"Product D\", \"price\": 30, \"category\": \"Home\"},\n",
    "    {\"name\": \"Product E\", \"price\": 90, \"category\": \"Sports\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Agz3cP7Ppkzl"
   },
   "source": [
    "Use `map`, `reduce` and `filter` that produce an output like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "LbFtUV_apkzl",
    "outputId": "745cdcbe-7320-4a08-de7b-0e1bcb84473e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'category': 'Electronics', 'average_price': 50.0},\n",
       " {'category': 'Sports', 'average_price': 90.0}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    {\"category\": \"Electronics\", \"average_price\": 50.0},\n",
    "    {\"category\": \"Sports\", \"average_price\": 90.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKBEAQE3pkzl"
   },
   "source": [
    "### Test\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1732181933353,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "0qj_9nZSpkzm",
    "outputId": "7bab35c7-84d0-4603-a1da-dc4a76768179"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Product 1', 'price': 109, 'category': 'Books'},\n",
       " {'name': 'Product 2', 'price': 191, 'category': 'Sports'},\n",
       " {'name': 'Product 3', 'price': 31, 'category': 'Sports'},\n",
       " {'name': 'Product 4', 'price': 89, 'category': 'Home'},\n",
       " {'name': 'Product 5', 'price': 175, 'category': 'Books'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_product_dataset(num_products=100):\n",
    "    categories = [\"Electronics\", \"Home\", \"Sports\", \"Books\", \"Clothing\", \"Toys\"]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": f\"Product {i}\",\n",
    "            \"price\": randint(10, 200),  # Random price between 10 and 200\n",
    "            \"category\": choice(categories),  # Randomly choose a category\n",
    "        }\n",
    "        for i in range(1, num_products + 1)\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "# Example of using the function\n",
    "random_dataset = generate_random_product_dataset(100)\n",
    "random_dataset[:5]  # Display the first 5 entries to check the dataset structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "AG9V3Wt7pkzm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 'Sports', 'average_price': 106.0}\n",
      "{'category': 'Toys', 'average_price': 154.0}\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "# hints: 1) Group products by category (you don't need to use map reduce for this part), then 2) use map reduce paradigm to\n",
    "# calculate the average price for each category and filter categories with an average price > 50\n",
    "\n",
    "from functools import reduce\n",
    "products = [{'name': 'Product 1', 'price': 106, 'category': 'Sports'},\n",
    " {'name': 'Product 2', 'price': 121, 'category': 'Toys'},\n",
    " {'name': 'Product 3', 'price': 10, 'category': 'Home'},\n",
    " {'name': 'Product 4', 'price': 187, 'category': 'Toys'},\n",
    " {'name': 'Product 5', 'price': 35, 'category': 'Electronics'}\n",
    "]\n",
    "\n",
    "category_groups = {}\n",
    "for product in products:\n",
    "    category = product['category']\n",
    "    if category not in category_groups:\n",
    "        category_groups[category] = []\n",
    "    category_groups[category].append(product)\n",
    "\n",
    "def calculate_avg_price(category_products):\n",
    "    total_price = reduce(lambda acc, product: acc + product['price'], category_products, 0)\n",
    "    avg_price = total_price / len(category_products)\n",
    "    return {'category' : category_products[0]['category'], 'average_price': avg_price}\n",
    "\n",
    "category_avg_prices = list(map(calculate_avg_price, category_groups.values()))\n",
    "\n",
    "high_avg_price_categories = list(filter(lambda category: category['average_price'] > 50, category_avg_prices ))\n",
    "\n",
    "for category in high_avg_price_categories:\n",
    "    print(category)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hivtZEf7pkzm"
   },
   "source": [
    "# Exercise 3\n",
    "\n",
    "You have a list of dictionaries, each representing an employee with the following properties: name, salary, and department. Your task is to use `map`, `filter`, and `reduce` to calculate the average salary for each department and return a list of dictionaries containing only the departments where the average salary is above 65,000.\n",
    "\n",
    "**Example Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1732181936402,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "N8vjLRHxpkzm"
   },
   "outputs": [],
   "source": [
    "employees = [\n",
    "    {\"name\": \"John\", \"salary\": 70000, \"department\": \"Engineering\"},\n",
    "    {\"name\": \"Jane\", \"salary\": 75000, \"department\": \"Engineering\"},\n",
    "    {\"name\": \"Alice\", \"salary\": 60000, \"department\": \"HR\"},\n",
    "    {\"name\": \"Bob\", \"salary\": 68000, \"department\": \"HR\"},\n",
    "    {\"name\": \"Charlie\", \"salary\": 90000, \"department\": \"Marketing\"},\n",
    "    {\"name\": \"Diana\", \"salary\": 50000, \"department\": \"Marketing\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otSniMO7pkzm"
   },
   "source": [
    "Use `map`, `reduce` and `filter` that produce an output like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Kx4HT8RXpkzn",
    "outputId": "8653ff13-815d-4040-c68e-fc4a6825134d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'department': 'Engineering', 'average_salary': 72500.0},\n",
       " {'department': 'Marketing', 'average_salary': 70000.0}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    {\"department\": \"Engineering\", \"average_salary\": 72500.0},\n",
    "    {\"department\": \"Marketing\", \"average_salary\": 70000.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GD_xlB78pkzn"
   },
   "source": [
    "### Test\n",
    "\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1732181939215,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "RhR9JLK-pkzn",
    "outputId": "72bc934d-4d3c-477e-cf84-3cf1d8fae61a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Employee 1', 'salary': 54644, 'department': 'Sales'},\n",
       " {'name': 'Employee 2', 'salary': 78195, 'department': 'HR'},\n",
       " {'name': 'Employee 3', 'salary': 98315, 'department': 'Finance'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_employee_dataset(num_employees=50):\n",
    "    departments = [\"Engineering\", \"HR\", \"Marketing\", \"Sales\", \"Finance\", \"IT\"]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": f\"Employee {i}\",\n",
    "            \"salary\": randint(40000, 120000),  # Random salary between 40,000 and 120,000\n",
    "            \"department\": choice(departments)  # Randomly choose a department\n",
    "        }\n",
    "        for i in range(1, num_employees + 1)\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "random_employee_dataset = generate_random_employee_dataset(50)\n",
    "\n",
    "random_employee_dataset[:3]  # Display the first 3 entries of each dataset for checking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "pt9m6NK-pkzo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'department': 'Marketing', 'average_salary': 101509.5}\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "# hints: 1) Group employees' salaries by department (you don't need to use map reduce for this part), then 2) use map reduce paradigm to\n",
    "# calculate the average salary for each department and filter departments with an average salary > threshold\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "employees = [ {'name': 'Employee 1', 'salary': 55873, 'department': 'HR'},\n",
    " {'name': 'Employee 2', 'salary': 88826, 'department': 'Marketing'},\n",
    " {'name': 'Employee 3', 'salary': 114193, 'department': 'Marketing'}\n",
    "]\n",
    "\n",
    "department_groups = {}\n",
    "for employee in employees:\n",
    "    department = employee['department']\n",
    "    if department not in department_groups:\n",
    "        department_groups[department] = []\n",
    "    department_groups[department].append(employee['salary'])\n",
    "\n",
    "def calculate_avg_salary(salaries):\n",
    "    total_salary = reduce(lambda acc, salary: acc + salary, salaries, 0)\n",
    "    avg_salary = total_salary / len(salaries)\n",
    "    return avg_salary \n",
    "\n",
    "department_avg_salaries= [\n",
    "  {'department': department, 'average_salary': calculate_avg_salary(salaries)}\n",
    "  for department, salaries in department_groups.items()\n",
    "]\n",
    "\n",
    "treshold = 65000\n",
    "high_avg_salary_departments = list(filter(lambda dept: dept['average_salary'] > treshold, department_avg_salaries))\n",
    "\n",
    "for department in high_avg_salary_departments:\n",
    "    print(department)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzxr0v2Rpkzo"
   },
   "source": [
    "# Biopython\n",
    "\n",
    "Write the following five functions to analyze global alignments between two sequences using Biopython's `pairwise2` module:\n",
    "\n",
    "1. **countMatches(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment (pairwise2.globalxx) of the same length. It returns the number of positions where the elements of both sequences match.\n",
    "\n",
    "2. **countMismatches(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of positions where the elements of the two sequences are different (i.e., they are not gaps, and the characters do not match).\n",
    "\n",
    "3. **countGapOpens(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of gap openings in the alignment (a gap is opened when a '-' appears in the sequence).\n",
    "\n",
    "4. **countGapExtensions(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of gap extensions (where '-' continues in the alignment after an initial gap is opened).\n",
    "\n",
    "5. **getScore(s1, s2, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment and returns the alignment score based on the provided scoring scheme: `matchScore` for matches, `mismatchPenalty` for mismatches, `gapOpenPenalty` for opening a gap, and `gapExtensionPenalty` for extending a gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "5PIaf6BUpkzo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is sequence 1:\n",
      "MCPARSLLLVATLVLLDHLSLARNLPVATPDPGMFPCLHHSQNLLRAVSNMLQKARQTLEFYPCTSEEIDHEDITKDKTSTVEACLPLELTKNESCLNSRETSFITNGSCLASRKTSFMMALCLSSIYEDLKMYQVEFKTMNAKLLMDPKRQIFLDQNMLAVIDELMQALNFNSETVPQKSSLEEPDFYKTKIKLCILLHAFRIRAVTIDRVMSYLNAS\n",
      "this is sequence 2:\n",
      "MCHQQLVISWFSLVFLASPLVAIWELKKDVYVVELDWYPDAPGEMVVLTCDTPEEDGITWTLDQSSEVLGSGKTLTIQVKEFGDAGQYTCHKGGEVLSHSLLLLHKKEDGIWSTDILKDQKEPKNKTFLRCEAKNYSGRFTCWWLTTISTDLTFSVKSSRGSSDPQGVTCGAATLSAERVRGDNKEYEYSVECQEDSACPAAEESLPIEVMVDAVHKLKYENYTSSFFIRDIIKPDPPKNLQLKPLKNSRQVEVSWEYPDTWSTPHSYFSLTFCVQVQGKSKREKKDRVFTDKTSATVICRKNASISVRAQDRYYSSSWSEWASVPCS\n"
     ]
    }
   ],
   "source": [
    "# Add your functions here\n",
    "\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "\n",
    "#1 countMatches\n",
    "def countMatches(s1, s2):\n",
    "    alignment = pairwise2.align.globalxx(s1, s2)[0]\n",
    "    aligned_s1, aligned_s2 = alignment.seqA, alignment.seqB\n",
    "    matches= sum(1 for a, b in zip(aligned_s1, aligned_s2) if a == b and a != '-')\n",
    "    return matches\n",
    "\n",
    "#2 countMismatches\n",
    "def countMismatches(s1, s2):\n",
    "    alignment = pairwise2.align.globalxx(s1, s2)[0]\n",
    "    aligned_s1, aligned_s2 = alignment.seqA, alignment.seqB\n",
    "    mismatches = sum(1 for a, b in zip(aligned_s1, aligned_s2) if a != b and a != '-' and b != '-')\n",
    "    return mismatches\n",
    "\n",
    "#3 countGapOpens\n",
    "def countGapOpens(s1, s2):\n",
    "    alignment = pairwise2.align.globalxx(s1, s2)[0]\n",
    "    aligned_s1, aligned_s2 = alignment.seqA, alignment.seqB\n",
    "    gaps = sum(1 for i in range(1, len(aligned_s1)) if aligned_s1[i] == '-' and aligned_s1[i-1] != '-')\n",
    "    gaps += sum( 1 for i in range(1, len(aligned_s2))if aligned_s2[i] == '-' and aligned_s2[i-1] != '-')\n",
    "    return gaps \n",
    "    \n",
    "#4 countGapExtensions\n",
    "def countGapExtensions(s1, s2):\n",
    "    alignment = pairwise2.align.globalxx(s1, s2)[0]\n",
    "    aligned_s1, aligned_s2 = alignment.seqA, alignment.seqB\n",
    "    extensions = sum(1 for i in range(1, len(aligned_s1))if aligned_s1[i] == '-' and aligned_s1[i-1] == '-')\n",
    "    extensions += sum( 1 for i in range(1, len(aligned_s2))if aligned_s2[i] == '-' and aligned_s2[i-1] != '-')\n",
    "    return extensions \n",
    "\n",
    "#5 getScore\n",
    "def getScore(s1, s2, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty):\n",
    "    alignment = pairwise2.align.globalms(s1, s2, matchScore, mismastchPenalty, gapOpenPenalty, gapExtensionPenalty)[0]\n",
    "    return alignment.score\n",
    "\n",
    "#try the commands and see if they work\n",
    "from Bio import SeqIO\n",
    "sequence_1 = str(next(SeqIO.parse(\"IL12A.fasta\", \"fasta\")).seq)\n",
    "sequence_2 = str(next(SeqIO.parse(\"IL12B.fasta\", \"fasta\")).seq)\n",
    "print(\"this is sequence 1:\")\n",
    "print(sequence_1)\n",
    "print(\"this is sequence 2:\")\n",
    "print(sequence_2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81O19v1fpkzo"
   },
   "source": [
    "### Test\n",
    "Align the sequences of the [Interleukin-12](https://en.wikipedia.org/wiki/Interleukin_12) chain A (denoted as `s1`) from the file [`IL12A.fasta`](https://qcbsciprolab2020.readthedocs.io/en/latest/file_samples/IL12A.fasta) and the Interleukin-12 chain B (denoted as `s2`) from the file [`IL12B.fasta`](https://qcbsciprolab2020.readthedocs.io/en/latest/file_samples/IL12B.fasta) and check the score as computed from pairwise2 and from your functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ZBhfr3jepkzp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MCHQQLVISWFSLVFLASPLVAIWELKKDVYVVELDWYPDAPGEMVVLTCDTPEEDGITWTLDQSSEVLGSGKTLTIQVKEFGDAGQYTCHKGGEVLSHSLLLLHKKEDGIWSTDILKDQKEPKNKTFLRCEAKNYSGRFTCWWLTTISTDLTFSVKSSRGSSDPQGVTCGAATLSAERVRGDNKEYEYSVECQEDSACPAAEESLPIEVMVDAVHKLKYENYTSSFFIRDIIKPDPPKNLQLKPLKNSRQVEVSWEYPDTWSTPHSYFSLTFCVQVQGKSKREKKDRVFTDKTSATVICRKNASISVRAQDRYYSSSWSEWASVPCS'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the output of the test here\n",
    "'this is sequence 1:'\n",
    "'MCPARSLLLVATLVLLDHLSLARNLPVATPDPGMFPCLHHSQNLLRAVSNMLQKARQTLEFYPCTSEEIDHEDITKDKTSTVEACLPLELTKNESCLNSRETSFITNGSCLASRKTSFMMALCLSSIYEDLKMYQVEFKTMNAKLLMDPKRQIFLDQNMLAVIDELMQALNFNSETVPQKSSLEEPDFYKTKIKLCILLHAFRIRAVTIDRVMSYLNAS'\n",
    "'this is sequence 2:'\n",
    "'MCHQQLVISWFSLVFLASPLVAIWELKKDVYVVELDWYPDAPGEMVVLTCDTPEEDGITWTLDQSSEVLGSGKTLTIQVKEFGDAGQYTCHKGGEVLSHSLLLLHKKEDGIWSTDILKDQKEPKNKTFLRCEAKNYSGRFTCWWLTTISTDLTFSVKSSRGSSDPQGVTCGAATLSAERVRGDNKEYEYSVECQEDSACPAAEESLPIEVMVDAVHKLKYENYTSSFFIRDIIKPDPPKNLQLKPLKNSRQVEVSWEYPDTWSTPHSYFSLTFCVQVQGKSKREKKDRVFTDKTSATVICRKNASISVRAQDRYYSSSWSEWASVPCS'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
